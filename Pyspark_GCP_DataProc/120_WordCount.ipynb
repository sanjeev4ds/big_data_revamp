{"cells": [{"cell_type": "code", "execution_count": 1, "id": "96f91ceb-57b0-4d8e-97f5-23426a06746e", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/03/21 09:15:22 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n                                                                                \r"}, {"data": {"text/plain": "['word1 word2 word3',\n 'word2 word3 word2',\n 'word1 word3 word1',\n 'word3 word2 word3']"}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder \\\n.appName(\"120_Spark_Sessions\") \\\n.master(\"yarn\") \\\n.getOrCreate()\n\nhdfs_file_path = \"/tmp/inputhdfsdbz.txt\"\nrdd_input_file = spark.sparkContext.textFile(hdfs_file_path)\nrdd_input_file.collect()"}, {"cell_type": "code", "execution_count": 2, "id": "cf2cf61f-60e1-4e79-8d91-d7ee33349db2", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "[('word3', 5), ('word2', 4), ('word1', 3)]"}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": "rdd_input_file = rdd_input_file.flatMap( lambda x: x.split(\" \"))\\\n.map(lambda x: (x,1))\\\n.reduceByKey(lambda a,b: a+b)\nrdd_input_file.collect()"}, {"cell_type": "code", "execution_count": null, "id": "a7773a70-f33b-4930-92dd-7a0922e1f79d", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}